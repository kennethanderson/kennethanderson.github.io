layout: columns-2
Sections:
- Title: Neo
  Subtitle: Avidbots
  Image: "images/neo.jpg"
  Markdown: |
    I cofounded Avidbots in 2014.  I wrote the software framework for two large-scale commercial floor-cleaning robots.  This framework includes components for motion planning, communication, visualization, live view, and control.  The motion planner encompasses the  most complexity, containing a complete coverage planning algorithm, dynamic and static constraints, and dynamic obstacle avoidance.  Avidbots was a 2014 Haxlr8r incubator participant, a 2014 Robot Launch semifinalist, has raised multiple rounds, and has over 80 employees.

- Title: PR2
  Subtitle: Willow Garage
  Image: "images/ArmPlanning.png"
  Markdown: |
    I improved the arm navigation stack by gathering statistics for comparing motion-planning algorithms; creating a very fast time parametrization algorithm that enforces dynamic constraints (velocity and acceleration) on a given trajectory; and improving distance field calculations by using incremental updates.  The filter and incremental updates improved the speed of the existing components by 100-fold and 30-fold, respectively.  This work is now a key component in the trajectory planning portion of the  open source ROS (Robot Operating System) and MoveIt library, which is used by over 65 robots.

- Title: Space Station Remote Manipulator System
  Subtitle: Queen's University
  Image: "images/SSRMS.png"
  Markdown: |
    I worked in the Robotics and Computer Vision Laboratory under the supervision of Dr. Michael Greenspan.  I implemented Greenspan's patented collision detection algorithm and visualization system for use with MD Robotics' SSRMS (aka. Canadarm2(R)).  This technique used specialized representations of objects (spheres and voxels) in order to perform real-time collision detection on an embedded system.  Results were published Symposium on Robot Design, Dynamics and Control, 2004.

- Title: Deep Green
  Subtitle: Queen's University
  Image: "images/deepGreen2.JPG"
  Markdown: |
    I worked on multiple aspects of the robotic pool-playing robot Deep Green(TM).  I used image processing techniques to localize the pool balls on the surface of the table.  I implemented lighting strategies to minimize shadows affecting the computer vision.  I investigated a new calibration technique for a local, cue-mounted camera.  Additionally, I developed a simulated environment to test out my AI shot strategies.  We were featured on the the Discovery Channel, Slashdot, and YouTube.

- Title: Kato
  Subtitle: University of Alberta
  Image: "images/kato3.jpg"
  Markdown: |
    Our team modified Kato(TM), a robotic Segway, to geocache (navigate from one GPS location to another). I taught the robot to access terrain drivability through a series of structured crash-tests. Our final field test was shown again on the Discovery Channel and the Edmonton Journal.

